# Puru Ojha

ðŸ“ž +91 7597500051  
ðŸ“§ [puru.ojha@research.iiit.ac.in](mailto:puru.ojha@research.iiit.ac.in)  
ðŸ”— [LinkedIn](https://www.linkedin.com/in/puru-ojha-a27632166/) | [GitHub](https://github.com/puru-ojha)

---

## Research Interests

Robot learning for long-horizon manipulation tasks, with a focus on zero-shot policy transfer, language-grounded perception, and developing neuro-symbolic systems that combine the generalization of deep learning with the verifiability and safety of formal methods.

---

## Education

**International Institute of Information Technology, Hyderabad**  
*Master of Science By Research in Computer Science and Engineering* (8.3 CGPA)  
Telangana, India | 2022 â€“ Current  
GRE: 322 (Quant: 169, Verbal: 153)

**The LNM Institute of Information Technology**  
*Bachelor of Technology in Mechanical Engineering, Specialization in Mechatronics*  
Rajasthan, India | 2014 â€“ 2018

---

## Research Projects

### Zero-Shot Policy Transfer for Cross-Embodiment Robotic Manipulation
- Developed a zero-shot policy transfer framework for cross-embodiment manipulation, enabling a generalist policy (Ï€â‚€) trained on Franka Panda data to control a morphologically distinct uFactory xArm without any fine-tuning.
- Implemented a Brownian bridge diffusion model for visual domain adaptation, translating sensory inputs from the target robot (xArm) to the source domain (Panda) for seamless, real-time policy execution.
- Engineered a robust policy transfer pipeline that leverages real-world data, addressing generalization challenges across different robot hardware and environments.

### Sequential Rearrangement Planning with Language-Guided Graph Transformer
- Designed a graph-based transformer model for predicting object removal sequences in cluttered tabletop scenes, conditioned on natural language goals.
- Built a large-scale simulation and training pipeline with expert A* supervision and PPO fine-tuning, achieving state-of-the-art performance over GRN and NRP baselines.

### Enhanced Transformer-Based Framework for Grounded Image Situation Recognition
- Developed a transformer framework for grounded situation recognition to enable robots to follow complex natural language instructions.
- Improved noun grounding and verb prediction by integrating CLIP and Faster-RCNN features into a CoFormer architecture, achieving state-of-the-art performance on the SWiG dataset.

### Procedural Generation of Architecturally Consistent Simulation Environment
- Engineered a framework for procedural generation of complex, structured environments for benchmarking RL agents and studying sim-to-real transfer of navigational policies.
- Designed a graph-based algorithm to generate scalable, architecturally consistent layouts with dynamic multi-path structures for realistic simulation.

---

## Research Publications

- **ACMGVR:** *Architecturally Consistent Mazes for Games in Virtual Reality* â€” In Proceedings of The Annual Symposium on Computer-Human Interaction in Play (CHI PLAY 2024).
- **The POMS Effect:** *Measuring the Impact of Overlapping Architectures on User Engagement in Virtual Reality* â€” In Proceedings of International Conference on Virtual Reality (ICVR 2025).

---

## Leadership & Mentorship Experience

- **AI Olympiad Coach, IIIT-H:** Coached Indiaâ€™s IOAI 2025 team; taught RL and motion planning bridging classical robotics with modern deep RL (DQN, PPO).
- **Teaching Assistant, Mobile Robotics, IIIT-H:** Supported instruction and projects on robot kinematics, SLAM, and path planning using ROS and Gazebo.

---

## Technical Skills

**Languages & Tools:** Python, C++, C#, Bash, Git, Linux, Tmux  
**Robotics & Simulation:** ROS, PyBullet, Gazebo, MoveIt, RViz, OpenCV, PCL, Unity, Blender  
**Deep Learning & RL:** PyTorch, Stable Baselines3, TensorFlow, CLIP, PointNet++, PyTorch Geometric, RLlib, HDF5

